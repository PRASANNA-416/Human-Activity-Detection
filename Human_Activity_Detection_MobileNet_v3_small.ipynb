{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOgJ4ZuQqp/AXc4mrct2gof",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRASANNA-416/Human-Activity-Detection-/blob/main/Human_Activity_Detection_MobileNet_v3_small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDl-qaFsQlGV",
        "outputId": "f1d2596f-9d13-4487-bc9e-4db4263793c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the training CSV file\n",
        "train_csv_path = '/content/gdrive/MyDrive/ML/Human Action Recognition/Training_set.csv'\n",
        "train_data = pd.read_csv(train_csv_path)\n",
        "\n",
        "# Load the testing CSV file\n",
        "test_csv_path = '/content/gdrive/MyDrive/ML/Human Action Recognition/testing_set.csv'\n",
        "test_data = pd.read_csv(test_csv_path)"
      ],
      "metadata": {
        "id": "iubxFwHQQrDC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the CSV files\n",
        "train_csv_path = '/content/gdrive/MyDrive/ML/Human Action Recognition/Training_set.csv'\n",
        "test_csv_path = '/content/gdrive/MyDrive/ML/Human Action Recognition/testing_set.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_csv_path)\n",
        "test_data = pd.read_csv(test_csv_path)\n",
        "\n",
        "# Define the target image size and batch size\n",
        "target_size = (224, 224)  # Adjust according to your requirements\n",
        "batch_size = 32\n",
        "\n",
        "# Create ImageDataGenerators with preprocessing options\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,  # Normalize pixel values between 0 and 1\n",
        "    rotation_range=20,  # Randomly rotate images by 20 degrees\n",
        "    width_shift_range=0.2,  # Randomly shift the width by 20%\n",
        "    height_shift_range=0.2,  # Randomly shift the height by 20%\n",
        "    horizontal_flip=True  # Randomly flip images horizontally\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Create train and test generators\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_data,\n",
        "    directory='/content/gdrive/MyDrive/ML/Human Action Recognition/train',  # Directory containing the train images\n",
        "    x_col='filename',  # Column name for the filenames\n",
        "    y_col='label',  # Column name for the labels\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_data,\n",
        "    directory='/content/gdrive/MyDrive/ML/Human Action Recognition/test',\n",
        "    x_col='filename',  # Column name for the filenames\n",
        "    y_col='label',  # Column name for the labels\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Check the class indices assigned by the generator\n",
        "class_indices = test_generator.class_indices\n",
        "print(class_indices)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqu40rk8QrFs",
        "outputId": "f0713694-f83a-4780-dc3f-ff8a2ca783f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12100 validated image filenames belonging to 15 classes.\n",
            "Found 500 validated image filenames belonging to 15 classes.\n",
            "{'calling': 0, 'clapping': 1, 'cycling': 2, 'dancing': 3, 'drinking': 4, 'eating': 5, 'fighting': 6, 'hugging': 7, 'laughing': 8, 'listening_to_music': 9, 'running': 10, 'sitting': 11, 'sleeping': 12, 'texting': 13, 'using_laptop': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Define the model\n",
        "m = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\n",
        "        'https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5',\n",
        "        trainable=True),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(15, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Build the model with the default input shape\n",
        "m.build((None, 224, 224, 3))  # Batch input shape.\n",
        "\n",
        "# Print the model summary\n",
        "print(m.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeYqBEtpQrIQ",
        "outputId": "a68023d9-2903-4d7c-f4f0-8cf3521b0708"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1024)              1026552   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               262400    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 15)                3855      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,292,807\n",
            "Trainable params: 1,283,127\n",
            "Non-trainable params: 9,680\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "m.fit(train_generator, epochs=10,batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF0XE-ISQrLc",
        "outputId": "d399fa29-2f7a-42d3-864d-4b2e4c3b573d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "379/379 [==============================] - 3020s 8s/step - loss: 1.8252 - accuracy: 0.4964\n",
            "Epoch 2/10\n",
            "379/379 [==============================] - 454s 1s/step - loss: 1.4431 - accuracy: 0.6134\n",
            "Epoch 3/10\n",
            "379/379 [==============================] - 462s 1s/step - loss: 1.2856 - accuracy: 0.6615\n",
            "Epoch 4/10\n",
            "379/379 [==============================] - 450s 1s/step - loss: 1.1897 - accuracy: 0.6978\n",
            "Epoch 5/10\n",
            "379/379 [==============================] - 456s 1s/step - loss: 1.1041 - accuracy: 0.7233\n",
            "Epoch 6/10\n",
            "379/379 [==============================] - 451s 1s/step - loss: 1.0323 - accuracy: 0.7383\n",
            "Epoch 7/10\n",
            "379/379 [==============================] - 449s 1s/step - loss: 0.9727 - accuracy: 0.7578\n",
            "Epoch 8/10\n",
            "379/379 [==============================] - 451s 1s/step - loss: 0.9456 - accuracy: 0.7650\n",
            "Epoch 9/10\n",
            "379/379 [==============================] - 463s 1s/step - loss: 0.8967 - accuracy: 0.7820\n",
            "Epoch 10/10\n",
            "379/379 [==============================] - 454s 1s/step - loss: 0.8557 - accuracy: 0.7977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc32fe8c040>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Evaluate the model on the test generator\n",
        "test_loss, test_accuracy = m.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1CgErK1QrNz",
        "outputId": "2b3dc2a7-07e3-4e99-e50f-eaaf089cbde4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 110s 7s/step - loss: 1.3710 - accuracy: 0.6620\n",
            "Test Loss: 1.3710390329360962\n",
            "Test Accuracy: 0.6620000004768372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.save_weights('mobileNetv3small.h5')"
      ],
      "metadata": {
        "id": "gbJMS8s0qynf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('mobileNetv3small.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-rSJELPLq8eU",
        "outputId": "8992b7ec-0fb0-43cf-b691-d16962d7435c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5f86b346-2343-4c2c-a832-aec1078d51b5\", \"mobileNetv3small.h5\", 5375776)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j9afNyMlrGM2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}